{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPH/amY5Sij8tKLqBvHVurK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjwmOZyMdCED","executionInfo":{"status":"ok","timestamp":1685466560566,"user_tz":-330,"elapsed":5332,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}},"outputId":"b760202b-1dbe-4c37-9a6f-21fc173d5a86"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import csv\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","from rake_nltk import Rake\n","from gensim import corpora\n","from gensim.models import LdaModel"],"metadata":{"id":"Qn9u4jb_dNf2","executionInfo":{"status":"ok","timestamp":1685466643399,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Load text from CSV file\n","def load_text(csv_file):\n","    with open(csv_file, 'r', encoding='utf-8') as file:\n","        reader = csv.reader(file)\n","        next(reader)  # Skip header row\n","\n","        for row in reader:\n","            text = row[0]\n","\n","    return text"],"metadata":{"id":"YS-yWwWodQHz","executionInfo":{"status":"ok","timestamp":1685466645692,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Preprocess text\n","def preprocess_text(text):\n","    # Tokenize the text using word_tokenize from NLTK\n","    tokens = word_tokenize(text)\n","    \n","    # Add your additional preprocessing steps here (e.g., lowercase, stop words removal, etc.)\n","    processed_text = [token.lower() for token in tokens]\n","\n","    return processed_text"],"metadata":{"id":"M68jice6dRO7","executionInfo":{"status":"ok","timestamp":1685466645693,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Function to extract keywords from text\n","def extract_keywords(text, num_keywords):\n","    # Create a Rake object\n","    r = Rake()\n","\n","    # Extract keywords\n","    r.extract_keywords_from_text(text)\n","\n","    # Get the top-ranked phrases as keywords\n","    keywords_list = r.get_ranked_phrases_with_scores()[:num_keywords]\n","\n","    return keywords_list"],"metadata":{"id":"M01dMHeRdRP6","executionInfo":{"status":"ok","timestamp":1685467027167,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Function to perform topic modeling\n","def perform_topic_modeling(processed_text, num_topics):\n","    # Create dictionary and corpus\n","    dictionary = corpora.Dictionary([processed_text])\n","    corpus = [dictionary.doc2bow(processed_text)]\n","\n","    # Perform LDA topic modeling\n","    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n","\n","    # Get the top keywords for each topic\n","    topics = lda_model.print_topics(num_topics=num_topics, num_words=num_keywords)\n","\n","    return topics"],"metadata":{"id":"8EOts24tdXEd","executionInfo":{"status":"ok","timestamp":1685466645696,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OlMZANqcdgPZ","executionInfo":{"status":"ok","timestamp":1685466645697,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}},"outputId":"242f9a73-4c32-4c5d-a451-0b3ab6d8c292"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhKIZWlOaLeE","executionInfo":{"status":"ok","timestamp":1685467044912,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}},"outputId":"6224c04d-bb9c-44ed-af9c-906a30aeba41"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"output_type":"stream","name":"stdout","text":["Keywords:\n","approach machine learning approach data analysis approach table 2 show\n","approach machine learning approach data analysis approach table 1 show\n","new loan value comparison data analysis machine learningabove figure shows\n","1stjul 2021 â€“ 30th jun 2022\n","security finance new loan dataset using intraday dataset\n","\n","Topics:\n","(0, '0.035*\"the\" + 0.031*\"new\" + 0.028*\"and\" + 0.027*\".\" + 0.027*\"for\"')\n","(1, '0.035*\".\" + 0.031*\"data\" + 0.028*\"for\" + 0.026*\"loan\" + 0.024*\"the\"')\n","(2, '0.033*\".\" + 0.030*\"for\" + 0.029*\"the\" + 0.027*\"new\" + 0.024*\"loan\"')\n","(3, '0.041*\".\" + 0.040*\"loan\" + 0.035*\"the\" + 0.029*\"for\" + 0.029*\"new\"')\n","(4, '0.032*\"the\" + 0.028*\"for\" + 0.026*\".\" + 0.023*\"data\" + 0.021*\"new\"')\n","(5, '0.022*\"for\" + 0.021*\".\" + 0.020*\"the\" + 0.018*\"new\" + 0.016*\"data\"')\n","(6, '0.026*\".\" + 0.021*\"for\" + 0.020*\"data\" + 0.018*\",\" + 0.017*\"and\"')\n","(7, '0.036*\"for\" + 0.034*\".\" + 0.027*\",\" + 0.026*\"the\" + 0.024*\"data\"')\n","(8, '0.026*\"data\" + 0.026*\"for\" + 0.025*\"and\" + 0.024*\"the\" + 0.020*\"new\"')\n","(9, '0.039*\".\" + 0.038*\"for\" + 0.029*\"data\" + 0.028*\"new\" + 0.026*\"loan\"')\n"]}],"source":["# Define CSV file path\n","csv_file = \"/content/drive/MyDrive/Colab Notebooks/NLP/text.csv\"\n","\n","# Define the number of keywords and topics\n","num_keywords = 5\n","num_topics = 10\n","\n","# Load text from CSV\n","text = load_text(csv_file)\n","\n","# Preprocess text\n","processed_text = preprocess_text(text)\n","\n","# Extract keywords from text\n","keywords_list = extract_keywords(text, num_keywords)\n","\n","# Perform topic modeling\n","topics = perform_topic_modeling(processed_text, num_topics)\n","\n","# Print the extracted keywords\n","print(\"Keywords:\")\n","for score,keyword in keywords_list:\n","    print(keyword)\n","\n","# Print the topics and their keywords\n","print(\"\\nTopics:\")\n","for topic in topics:\n","    print(topic)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"RpzMPnyRowqD"},"execution_count":null,"outputs":[]}]}