{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPRqnULdzL6Un37xHKVGvaQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import csv\n","import string\n","from collections import Counter\n","from PyPDF2 import PdfReader\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize"],"metadata":{"id":"LTOxGe2EPVVB","executionInfo":{"status":"ok","timestamp":1685463857075,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Function to extract text from a PDF\n","def extract_text_from_pdf(pdf_file):\n","    text = \"\"\n","\n","    with open(pdf_file, 'rb') as file:\n","        reader = PdfReader(file)\n","\n","        for page in reader.pages:\n","            text += page.extract_text()\n","\n","    return text"],"metadata":{"id":"qQDDZJzwPVWP","executionInfo":{"status":"ok","timestamp":1685463857568,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Function to store text in a CSV file\n","def save_text_to_csv(text, csv_file):\n","    with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Text'])\n","        writer.writerow([text])\n","\n","    print(\"Text saved to\", csv_file)"],"metadata":{"id":"qNSXKGhQPjwM","executionInfo":{"status":"ok","timestamp":1685463857568,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Function to find the most repeated word in the text, excluding stopwords and punctuations\n","def find_most_repeated_word(text):\n","    # Tokenize the text\n","    words = word_tokenize(text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    words = [word for word in words if word.lower() not in stop_words]\n","\n","    # Remove punctuations\n","    words = [word for word in words if word not in string.punctuation]\n","\n","    # Count word occurrences\n","    word_counts = Counter(words)\n","    most_common_word = word_counts.most_common(1)\n","\n","    return most_common_word[0][0]"],"metadata":{"id":"w11up0L-Pj3A","executionInfo":{"status":"ok","timestamp":1685463858015,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdX5vlF2ZasT","executionInfo":{"status":"ok","timestamp":1685463859130,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}},"outputId":"2a7da005-35e7-410b-b917-ed04359b17c0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WaCV1Si_Ot_v","executionInfo":{"status":"ok","timestamp":1685463864436,"user_tz":-330,"elapsed":719,"user":{"displayName":"Vashu Singhal","userId":"08183273977131733760"}},"outputId":"ac434882-0930-4ccc-d957-51dae469d5af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Text saved to text.csv\n","Most Repeated Word: Loan\n"]}],"source":["# Define PDF file path\n","pdf_file = \"/content/123.pdf\"\n","\n","# Define CSV file path\n","csv_file = \"text.csv\"\n","\n","# Extract text from PDF\n","text = extract_text_from_pdf(pdf_file)\n","\n","# Save text to CSV\n","save_text_to_csv(text, csv_file)\n","\n","# Find the most repeated word in the text\n","most_repeated_word = find_most_repeated_word(text)\n","\n","# Print the most repeated word\n","print(\"Most Repeated Word:\", most_repeated_word)\n","# Function to store text in a CSV file\n","def save_text_to_csv(text, csv_file):\n","    with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Text'])\n","        writer.writerow([text])\n","\n","    print(\"Text saved to\", csv_file)"]},{"cell_type":"code","source":[],"metadata":{"id":"jDfTNtjsPVbt"},"execution_count":null,"outputs":[]}]}